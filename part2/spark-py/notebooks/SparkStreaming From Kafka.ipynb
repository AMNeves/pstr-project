{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark streaming: Kafka example\n",
    "\n",
    "This is a simple example of how to run Spark Streaming jobs in Jupyter reading from Kafka.\n",
    "\n",
    "To run this example, you should first start the Kafka and Publisher provided for project 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkContext created!\n",
      "StreamingContext created!\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import socket\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "sc = SparkContext(\"local[2]\", \"KafkaExample\")\n",
    "print(\"SparkContext created!\")\n",
    "ssc = StreamingContext(sc, 5)\n",
    "print(\"StreamingContext created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines = KafkaUtils.createDirectStream(ssc, [\"debs\"], \\\n",
    "            {\"metadata.broker.list\": \"kafka:9092\"})\n",
    "# tut query\n",
    "\n",
    "lines = lines.window(15,5)\n",
    "\n",
    "lines.pprint()\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
